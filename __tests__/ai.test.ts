/**
 * Unit tests for the AI functionality, src/ai.ts
 *
 * To mock dependencies in ESM, you can create fixtures that export mock
 * functions and objects. For example, the openai module is mocked in this test,
 * so that the actual 'openai' module is not imported.
 */
import { jest } from '@jest/globals'
import * as openai from '../__fixtures__/openai.js'

// Mocks should be declared before the module being tested is imported.
jest.unstable_mockModule('openai', () => openai)

// The module being tested should be imported dynamically. This ensures that the
// mocks are used in place of any actual dependencies.
const { generateAIResponse } = await import('../src/ai.js')

describe('generateAIResponse', () => {
  const mockToken = 'test-token'
  const mockModel = 'gpt-4'
  const mockPrompt = 'test prompt'
  const mockSystemPrompt = 'test system prompt'

  beforeEach(() => {
    // Reset the mock implementation for each test
    openai.mockCreate.mockClear()
  })

  afterEach(() => {
    jest.resetAllMocks()
  })

  it('should generate an AI response successfully', async () => {
    const mockResponse = 'Test response'
    openai.mockCreate.mockResolvedValueOnce({
      id: 'chatcmpl-123',
      object: 'chat.completion',
      created: 1677652288,
      model: 'gpt-4',
      choices: [
        {
          message: {
            content: mockResponse,
            refusal: null,
            role: 'assistant'
          },
          finish_reason: 'stop',
          index: 0
        }
      ]
    })

    const response = await generateAIResponse(
      mockPrompt,
      mockSystemPrompt,
      mockModel,
      mockToken
    )

    expect(response).toBe(mockResponse)
    expect(openai.mockCreate).toHaveBeenCalledWith({
      model: mockModel,
      messages: [
        { role: 'system', content: mockSystemPrompt },
        { role: 'user', content: mockPrompt }
      ]
    })
  })

  it('should throw an error when no response is generated', async () => {
    openai.mockCreate.mockResolvedValueOnce({
      id: 'chatcmpl-123',
      object: 'chat.completion',
      created: 1677652288,
      model: 'gpt-4',
      choices: [
        {
          message: {
            content: null,
            refusal: null,
            role: 'assistant'
          },
          finish_reason: 'stop',
          index: 0
        }
      ]
    })

    await expect(
      generateAIResponse(mockPrompt, mockSystemPrompt, mockModel, mockToken)
    ).rejects.toThrow('No response was generated by the AI model')
  })

  it('should handle API errors properly', async () => {
    const errorMessage = 'API Error'
    openai.mockCreate.mockRejectedValueOnce(new Error(errorMessage))

    await expect(
      generateAIResponse(mockPrompt, mockSystemPrompt, mockModel, mockToken)
    ).rejects.toThrow(`Failed to generate AI response: ${errorMessage}`)
  })

  it('should handle undefined message', async () => {
    openai.mockCreate.mockResolvedValueOnce({
      id: 'chatcmpl-123',
      object: 'chat.completion',
      created: 1677652288,
      model: 'gpt-4',
      choices: [
        {
          message: undefined,
          finish_reason: 'stop',
          index: 0
        }
      ]
    })

    await expect(
      generateAIResponse(mockPrompt, mockSystemPrompt, mockModel, mockToken)
    ).rejects.toThrow('No response was generated by the AI model')
  })

  it('should handle empty choices array', async () => {
    openai.mockCreate.mockResolvedValueOnce({
      id: 'chatcmpl-123',
      object: 'chat.completion',
      created: 1677652288,
      model: 'gpt-4',
      choices: []
    })

    await expect(
      generateAIResponse(mockPrompt, mockSystemPrompt, mockModel, mockToken)
    ).rejects.toThrow('No response was generated by the AI model')
  })

  it('should generate AI response with structured output schema', async () => {
    const mockResponse = '{"message": "Test response"}'
    const schema = {
      type: 'object',
      properties: {
        message: { type: 'string' }
      },
      required: ['message']
    }

    openai.mockCreate.mockResolvedValueOnce({
      id: 'chatcmpl-123',
      object: 'chat.completion',
      created: 1677652288,
      model: 'gpt-4',
      choices: [
        {
          message: {
            content: mockResponse,
            refusal: null,
            role: 'assistant'
          },
          finish_reason: 'stop',
          index: 0
        }
      ]
    })

    const response = await generateAIResponse(
      mockPrompt,
      mockSystemPrompt,
      mockModel,
      mockToken,
      schema
    )

    expect(response).toBe(mockResponse)
    expect(openai.mockCreate).toHaveBeenCalledWith({
      model: mockModel,
      messages: [
        { role: 'system', content: mockSystemPrompt },
        { role: 'user', content: mockPrompt }
      ],
      response_format: {
        type: 'json_schema',
        json_schema: {
          name: 'structured_response',
          schema: schema,
          strict: true
        }
      }
    })
  })

  it('should generate AI response without schema when not provided', async () => {
    const mockResponse = 'Test response'
    openai.mockCreate.mockResolvedValueOnce({
      id: 'chatcmpl-123',
      object: 'chat.completion',
      created: 1677652288,
      model: 'gpt-4',
      choices: [
        {
          message: {
            content: mockResponse,
            refusal: null,
            role: 'assistant'
          },
          finish_reason: 'stop',
          index: 0
        }
      ]
    })

    const response = await generateAIResponse(
      mockPrompt,
      mockSystemPrompt,
      mockModel,
      mockToken
    )

    expect(response).toBe(mockResponse)
    expect(openai.mockCreate).toHaveBeenCalledWith({
      model: mockModel,
      messages: [
        { role: 'system', content: mockSystemPrompt },
        { role: 'user', content: mockPrompt }
      ]
    })
  })
})
