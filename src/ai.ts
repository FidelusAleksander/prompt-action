import { OpenAI } from "openai";

const SYSTEM_PROMPT = "You are a helpful assistant. Always provide direct answers or solutions without additional commentary.";

export interface TokenUsage {
  prompt_tokens: number;
  completion_tokens: number;
  total_tokens: number;
}

export interface AIResponseWithUsage {
  text: string;
  usage?: TokenUsage;
}

export async function generateAIResponse(
  prompt: string,
  model: string,
  token: string,
): Promise<AIResponseWithUsage> {
  const client = new OpenAI({
    baseURL: "https://models.inference.ai.azure.com",
    apiKey: token,
  });

  try {
    const completion = await client.chat.completions.create({
      model: model,
      messages: [
        { role: "system", content: SYSTEM_PROMPT },
        { role: "user", content: prompt }
      ],
    });

    const response = completion.choices[0]?.message?.content;
    if (!response) {
      throw new Error("No response was generated by the AI model");
    }

    return {
      text: response,
      usage: completion.usage
    };
  } catch (error) {
    throw new Error(
      `Failed to generate AI response: ${
        error instanceof Error ? error.message : String(error)
      }`,
    );
  }
}
