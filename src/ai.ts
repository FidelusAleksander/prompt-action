import { OpenAI } from 'openai'

export async function generateAIResponse(
  prompt: string,
  systemPrompt: string,
  model: string,
  token: string
): Promise<string> {
  const client = new OpenAI({
    baseURL: 'https://models.inference.ai.azure.com',
    apiKey: token
  })

  try {
    const completion = await client.chat.completions.create({
      model: model,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: prompt }
      ]
    })

    const response = completion.choices[0]?.message?.content
    if (!response) {
      throw new Error('No response was generated by the AI model')
    }

    return response
  } catch (error) {
    throw new Error(
      `Failed to generate AI response: ${
        error instanceof Error ? error.message : String(error)
      }`
    )
  }
}
