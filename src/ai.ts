import { OpenAI } from "openai";

export async function generateAIResponse(
  prompt: string,
  model: string,
  token: string,
): Promise<string> {
  const client = new OpenAI({
    baseURL: "https://models.inference.ai.azure.com",
    apiKey: token,
  });

  try {
    const completion = await client.chat.completions.create({
      model: model,
      messages: [{ role: "user", content: prompt }],
    });

    const response = completion.choices[0]?.message?.content;
    if (!response) {
      throw new Error("No response was generated by the AI model");
    }

    return response;
  } catch (error) {
    throw new Error(
      `Failed to generate AI response: ${
        error instanceof Error ? error.message : String(error)
      }`,
    );
  }
}
